# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eJ21n234wedYOubp1lJeWHKNey06KOne
"""

# ============================================================
# STREAMLIT APP : Time Series Forecasting (ARIMA / SARIMA)
# Objectifs :
# - Charger un CSV / Excel contenant une s√©rie temporelle
# - Visualiser : s√©rie, STL decomposition, test ADF (stationnarit√©)
# - Choisir mod√®le ARIMA ou SARIMA + param√©trer
# - Entra√Æner et pr√©voir N pas dans le futur
# - Afficher : graph pr√©vision + comparaison observ√© vs pr√©dit
#
# D√©pendances recommand√©es :
# pip install streamlit pandas numpy matplotlib statsmodels openpyxl
# ============================================================

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import io

from statsmodels.tsa.seasonal import STL
from statsmodels.tsa.stattools import adfuller

# ARIMA/SARIMA : dans statsmodels (API "SARIMAX" est la plus stable)
from statsmodels.tsa.statespace.sarimax import SARIMAX


# ------------------------------------------------------------
# CONFIG STREAMLIT
# ------------------------------------------------------------
st.set_page_config(
    page_title="Projet S√©rie Temporelle (ARIMA/SARIMA)",
    layout="wide"
)

st.title("üìà Application Streamlit - S√©rie temporelle (ARIMA / SARIMA)")
st.write(
    """
Cette application permet de charger un fichier **CSV ou Excel** contenant une s√©rie temporelle,
de la visualiser (courbe + STL), de tester la stationnarit√© (ADF), puis d'entra√Æner un mod√®le
**ARIMA ou SARIMA** pour produire une pr√©vision.
"""
)

# ------------------------------------------------------------
# FONCTIONS UTILES (avec beaucoup de commentaires)
# ------------------------------------------------------------

def read_file(uploaded_file):
    """
    Lecture robuste CSV/XLSX :
    - CSV: d√©tecte s√©parateur, encodage, g√®re virgule d√©cimale si besoin
    - XLSX: lecture classique
    """
    name = uploaded_file.name.lower()

    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(uploaded_file)

    if not name.endswith(".csv"):
        raise ValueError("Format non support√©. Merci d'uploader un CSV ou Excel.")

    # ---- Lecture CSV robuste ----
    # 1) On lit quelques octets pour deviner encodage
    raw = uploaded_file.getvalue()
    try:
        import chardet
        enc = chardet.detect(raw)["encoding"] or "utf-8"
    except Exception:
        enc = "utf-8"

    # 2) Tentative avec s√©parateur automatique (engine python)
    #    + fallback si souci
    try:
        df = pd.read_csv(
            io.BytesIO(raw),
            encoding=enc,
            sep=None,           # auto-d√©tection
            engine="python"
        )
        return df
    except Exception:
        # Fallback : essayer s√©parateurs courants
        for sep in [",", ";", "\t", "|"]:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc, sep=sep)
                return df
            except Exception:
                pass

    raise ValueError("Impossible de lire le CSV (encodage/s√©parateur).")



def parse_datetime_column(df: pd.DataFrame, date_col: str) -> pd.DataFrame:
    """
    Convertit la colonne date en datetime (si possible) puis trie.
    """
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
    # On supprime les lignes o√π la date n'est pas convertible
    df = df.dropna(subset=[date_col])
    # Tri chronologique
    df = df.sort_values(by=date_col)
    return df


def to_timeseries(df: pd.DataFrame, date_col: str, value_col: str, freq: str) -> pd.Series:
    """
    Transforme le DataFrame en Series temporelle :
    - index = dates
    - valeurs num√©riques
    - resampling √† une fr√©quence choisie (D, W, M, etc.)

    freq : fr√©quence pandas ("D"=jour, "W"=semaine, "M"=mois, "H"=heure...)
    """
    df = df.copy()

    # Conversion valeur en num√©rique (si texte -> NaN)
    df[value_col] = pd.to_numeric(df[value_col], errors="coerce")
    df = df.dropna(subset=[value_col])

    # Passage en index temporel
    df = df.set_index(date_col)

    # Resampling :
    # - Si tes donn√©es sont d√©j√† √† la bonne fr√©quence, √ßa ne change presque rien.
    # - Si plusieurs points par p√©riode : on agr√®ge (moyenne ici, mais on pourrait somme)
    ts = df[value_col].resample(freq).mean()

    # Gestion valeurs manquantes :
    # - pour des s√©ries temporelles, il est fr√©quent d'avoir des trous
    # - on peut interpoler ou forward-fill
    ts = ts.interpolate(method="time")

    return ts


def plot_series(ts: pd.Series, title: str):
    """
    Affiche une s√©rie temporelle avec matplotlib dans streamlit.
    """
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(ts.index, ts.values)
    ax.set_title(title)
    ax.set_xlabel("Date")
    ax.set_ylabel("Valeur")
    ax.grid(True)
    st.pyplot(fig)


def adf_test(ts: pd.Series) -> dict:
    """
    Test ADF (Augmented Dickey-Fuller) :
    - H0 : s√©rie non stationnaire
    - si p-value < 0.05 => on rejette H0 => stationnaire (souvent)
    """
    # adfuller attend une s√©rie sans NaN
    ts_clean = ts.dropna()

    result = adfuller(ts_clean, autolag="AIC")
    # result = (statistic, pvalue, usedlag, nobs, critical_values, icbest)

    output = {
        "statistic": result[0],
        "pvalue": result[1],
        "usedlag": result[2],
        "nobs": result[3],
        "critical_values": result[4],
        "icbest": result[5]
    }
    return output


def stl_decompose(ts: pd.Series, period: int):
    """
    STL decomposition :
    - p√©riode (seasonal period) √† fournir (ex: 7 si donn√©es journali√®res avec saison hebdo)
    """
    ts_clean = ts.dropna()

    # Robust=True g√®re mieux les outliers
    stl = STL(ts_clean, period=period, robust=True)
    res = stl.fit()
    return res


def fit_model(ts: pd.Series, model_type: str,
              order: tuple, seasonal_order: tuple):
    """
    Entra√Æne un mod√®le ARIMA/SARIMA via SARIMAX.
    - model_type : "ARIMA" ou "SARIMA"
    - order=(p,d,q)
    - seasonal_order=(P,D,Q,s) utilis√© si SARIMA, sinon on met (0,0,0,0)
    """
    ts_clean = ts.dropna()

    if model_type == "ARIMA":
        seasonal_order = (0, 0, 0, 0)

    # SARIMAX = mod√®le tr√®s g√©n√©ral :
    # - ARIMA si seasonal_order=(0,0,0,0)
    # - SARIMA si seasonal_order=(P,D,Q,s)
    model = SARIMAX(
        ts_clean,
        order=order,
        seasonal_order=seasonal_order,
        enforce_stationarity=False,  # on laisse le mod√®le g√©rer
        enforce_invertibility=False
    )

    fitted = model.fit(disp=False)
    return fitted


def forecast_and_plot(ts: pd.Series, fitted_model, steps: int, show_last_n: int):
    """
    Produit une pr√©vision future et affiche :
    - courbe observ√©e + forecast
    - comparaison observ√© vs pr√©dit sur la partie r√©cente (show_last_n points)
    """
    ts_clean = ts.dropna()

    # Pr√©vision future
    forecast_res = fitted_model.get_forecast(steps=steps)
    forecast_mean = forecast_res.predicted_mean
    forecast_ci = forecast_res.conf_int()

    # --------------------------------------------------------
    # Graph 1 : Observ√© + forecast + intervalle de confiance
    # --------------------------------------------------------
    fig1, ax1 = plt.subplots(figsize=(10, 4))

    ax1.plot(ts_clean.index, ts_clean.values, label="Observ√©")
    ax1.plot(forecast_mean.index, forecast_mean.values, label="Pr√©vision")

    # Intervalle de confiance (souvent 95%)
    ax1.fill_between(
        forecast_ci.index,
        forecast_ci.iloc[:, 0],
        forecast_ci.iloc[:, 1],
        alpha=0.2,
        label="IC"
    )

    ax1.set_title("Pr√©vision future")
    ax1.set_xlabel("Date")
    ax1.set_ylabel("Valeur")
    ax1.grid(True)
    ax1.legend()
    st.pyplot(fig1)

    # --------------------------------------------------------
    # Graph 2 : Comparaison Observ√© vs Pr√©dit sur une fen√™tre
    # (backtest simple : pr√©dictions in-sample sur les derniers points)
    # --------------------------------------------------------
    # On va g√©n√©rer des valeurs "fittedvalues" = pr√©dictions in-sample
    # Puis on affiche les N derniers points observ√©s vs pr√©dits.
    fitted_values = fitted_model.fittedvalues

    # Aligner indices (√ßa arrive que les indices diff√®rent)
    common_idx = ts_clean.index.intersection(fitted_values.index)
    ts_aligned = ts_clean.loc[common_idx]
    fv_aligned = fitted_values.loc[common_idx]

    # Prendre les derniers show_last_n points
    ts_recent = ts_aligned.tail(show_last_n)
    fv_recent = fv_aligned.tail(show_last_n)

    fig2, ax2 = plt.subplots(figsize=(10, 4))
    ax2.plot(ts_recent.index, ts_recent.values, label="Observ√© (r√©cent)")
    ax2.plot(fv_recent.index, fv_recent.values, label="Pr√©dit in-sample (r√©cent)")

    ax2.set_title(f"Comparaison Observ√© vs Pr√©dit (sur les {show_last_n} derniers points)")
    ax2.set_xlabel("Date")
    ax2.set_ylabel("Valeur")
    ax2.grid(True)
    ax2.legend()
    st.pyplot(fig2)

    return forecast_mean, forecast_ci


# ------------------------------------------------------------
# SIDEBAR : UPLOAD + PARAMS
# ------------------------------------------------------------
st.sidebar.header("‚öôÔ∏è Param√®tres")

uploaded_file = st.sidebar.file_uploader("1) Upload CSV ou Excel", type=["csv", "xlsx", "xls"])

if uploaded_file is None:
    st.info("‚¨ÖÔ∏è Commence par uploader un fichier CSV ou Excel dans la barre lat√©rale.")
    st.stop()

# Lecture du fichier
try:
    df = read_file(uploaded_file)
except Exception as e:
    st.error(f"Erreur lecture fichier : {e}")
    st.stop()

st.subheader("Aper√ßu des donn√©es")
st.dataframe(df.head(20))

# S√©lection des colonnes
st.sidebar.subheader("2) S√©lection des colonnes")
columns = df.columns.tolist()

date_col = st.sidebar.selectbox("Colonne Date/Temps", options=columns)
value_col = st.sidebar.selectbox("Colonne Valeur (num√©rique)", options=columns)

# Choix de fr√©quence
st.sidebar.subheader("3) Fr√©quence de la s√©rie")
freq = st.sidebar.selectbox(
    "Resampling (pandas freq)",
    options=["D", "W", "M", "H"],
    index=0,
    help="D=jour, W=semaine, M=mois, H=heure"
)

# Pr√©-traitement
df2 = parse_datetime_column(df, date_col)
ts = to_timeseries(df2, date_col, value_col, freq=freq)

# ------------------------------------------------------------
# VISUALISATION : S√©rie originale
# ------------------------------------------------------------
st.subheader("üìå S√©rie temporelle originale")
plot_series(ts, "S√©rie originale (apr√®s mise en forme + resampling)")

# ------------------------------------------------------------
# STL decomposition
# ------------------------------------------------------------
st.subheader("üß© D√©composition STL (tendance, saisonnalit√©, r√©sidu)")

# La p√©riode d√©pend de la fr√©quence :
# - si freq="D" (jour) : saison hebdomadaire => period=7
# - si freq="W" (semaine) : saison annuelle => period=52
# - si freq="M" (mois) : saison annuelle => period=12
# - si freq="H" (heure) : saison journali√®re => period=24
default_period_map = {"D": 7, "W": 52, "M": 12, "H": 24}
default_period = default_period_map.get(freq, 7)

period = st.number_input(
    "P√©riode saisonni√®re STL (ex: 7, 12, 24, 52...)",
    min_value=2,
    value=int(default_period),
    step=1
)

try:
    stl_res = stl_decompose(ts, period=period)

    # Affichage des composantes via matplotlib
    fig, axes = plt.subplots(4, 1, figsize=(10, 8), sharex=True)
    axes[0].plot(stl_res.observed)
    axes[0].set_title("Observed")
    axes[0].grid(True)

    axes[1].plot(stl_res.trend)
    axes[1].set_title("Trend (tendance)")
    axes[1].grid(True)

    axes[2].plot(stl_res.seasonal)
    axes[2].set_title("Seasonal (saisonnalit√©)")
    axes[2].grid(True)

    axes[3].plot(stl_res.resid)
    axes[3].set_title("Residual (r√©sidu)")
    axes[3].grid(True)

    plt.tight_layout()
    st.pyplot(fig)

except Exception as e:
    st.warning(f"Impossible de faire la STL decomposition : {e}")

# ------------------------------------------------------------
# ADF Test (Stationnarit√©)
# ------------------------------------------------------------
st.subheader("üß™ Test de stationnarit√© (ADF)")

try:
    adf_res = adf_test(ts)

    col1, col2 = st.columns(2)
    with col1:
        st.metric("ADF Statistic", f"{adf_res['statistic']:.4f}")
        st.metric("p-value", f"{adf_res['pvalue']:.6f}")
    with col2:
        st.write("Valeurs critiques :")
        st.json(adf_res["critical_values"])

    if adf_res["pvalue"] < 0.05:
        st.success("‚úÖ S√©rie probablement stationnaire (p-value < 0.05 : on rejette H0).")
    else:
        st.warning("‚ö†Ô∏è S√©rie probablement NON stationnaire (p-value ‚â• 0.05). ARIMA/SARIMA peuvent n√©cessiter diff√©renciation (d, D).")

except Exception as e:
    st.error(f"Erreur test ADF : {e}")

# ------------------------------------------------------------
# CHOIX MODELE + PARAMETRAGE
# ------------------------------------------------------------
st.subheader("ü§ñ Mod√©lisation (ARIMA / SARIMA)")

st.sidebar.subheader("4) Choix du mod√®le")
model_type = st.sidebar.selectbox("Mod√®le", options=["ARIMA", "SARIMA"])

st.sidebar.subheader("5) Param√®tres du mod√®le")

# ARIMA (p,d,q)
p = st.sidebar.number_input("p (AR)", min_value=0, max_value=10, value=1, step=1)
d = st.sidebar.number_input("d (Diff)", min_value=0, max_value=3, value=1, step=1)
q = st.sidebar.number_input("q (MA)", min_value=0, max_value=10, value=1, step=1)

order = (int(p), int(d), int(q))

# SARIMA (P,D,Q,s) si choisi
if model_type == "SARIMA":
    P = st.sidebar.number_input("P (Seasonal AR)", min_value=0, max_value=10, value=1, step=1)
    D = st.sidebar.number_input("D (Seasonal Diff)", min_value=0, max_value=3, value=1, step=1)
    Q = st.sidebar.number_input("Q (Seasonal MA)", min_value=0, max_value=10, value=1, step=1)

    # s = p√©riode saisonni√®re du mod√®le SARIMA
    # souvent m√™me logique que STL period
    s = st.sidebar.number_input("s (Season length)", min_value=0, value=int(default_period), step=1)
    seasonal_order = (int(P), int(D), int(Q), int(s))
else:
    seasonal_order = (0, 0, 0, 0)

# Pr√©vision
st.sidebar.subheader("6) Pr√©vision")
steps = st.sidebar.number_input("Nombre de pas dans le futur", min_value=1, max_value=500, value=30, step=1)
show_last_n = st.sidebar.number_input("Comparaison sur les N derniers points", min_value=10, max_value=500, value=60, step=10)

# Bouton "Run"
run = st.button("üöÄ Entra√Æner le mod√®le et pr√©dire")

if run:
    with st.spinner("Entra√Ænement du mod√®le..."):
        try:
            fitted = fit_model(ts, model_type=model_type, order=order, seasonal_order=seasonal_order)

            st.success("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")

            # R√©sum√© du mod√®le (texte)
            st.subheader("R√©sum√© du mod√®le (statsmodels)")
            st.text(fitted.summary())

            # Forecast + graphiques
            st.subheader("üìä R√©sultats : Pr√©vision & Comparaisons")
            forecast_mean, forecast_ci = forecast_and_plot(
                ts, fitted_model=fitted, steps=int(steps), show_last_n=int(show_last_n)
            )

            # Affichage tabulaire de la pr√©vision
            st.subheader("Table de pr√©vision")
            out_df = pd.DataFrame({
                "forecast": forecast_mean,
                "lower_ci": forecast_ci.iloc[:, 0],
                "upper_ci": forecast_ci.iloc[:, 1],
            })
            st.dataframe(out_df)

            # T√©l√©chargement CSV des forecasts
            csv_data = out_df.to_csv(index=True).encode("utf-8")
            st.download_button(
                label="‚¨áÔ∏è T√©l√©charger les pr√©visions (CSV)",
                data=csv_data,
                file_name="forecast.csv",
                mime="text/csv"
            )

        except Exception as e:
            st.error(f"‚ùå Erreur pendant l'entra√Ænement ou la pr√©vision : {e}")